# ğŸ“Š AnÃ¡lise de Consumo de Recursos - 10 UsuÃ¡rios + 100 Conversas SimultÃ¢neas

## ğŸ¯ CenÃ¡rio Analisado
- **UsuÃ¡rios WhatsApp:** 10 conexÃµes ativas
- **Clientes por usuÃ¡rio:** 10 clientes simultÃ¢neos
- **Total de conversas:** 100 conversas simultÃ¢neas
- **IA Opensource:** Ollama com Mistral 7B (padrÃ£o do projeto)
- **Arquitetura:** Docker Compose (6 serviÃ§os)

---

## ğŸ“ˆ Consumo de MemÃ³ria RAM por Componente

### 1ï¸âƒ£ **NestJS Backend**
```
Base:                    150 MB
Por conexÃ£o WebSocket:   10-15 MB
100 conexÃµes:            1.000-1.500 MB
Fila Bull (cache):       200-300 MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL Backend:           1.5-2.0 GB
```

**Justificativa:**
- Node.js v22 em produÃ§Ã£o usa ~150MB base
- Cada conexÃ£o WebSocket/HTTP mantÃ©m contexto em memÃ³ria
- Bull queue armazena jobs pendentes
- Sessions/contexto de conversa

---

### 2ï¸âƒ£ **PostgreSQL 16**
```
Base:                    250 MB
Shared Buffers (25%):    1.000-2.000 MB
Work Memory (100 conn):  500-800 MB
Cache Pages:             300-500 MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL PostgreSQL:        2.0-3.5 GB
```

**Justificativa:**
- shared_buffers = 25% de RAM total
- work_mem = memÃ³ria por operaÃ§Ã£o = 10-15MB Ã— 100 conexÃµes
- Ãndices + cache de queries
- Logs de transaÃ§Ã£o

---

### 3ï¸âƒ£ **Ollama (LLM Model)**
```
Modelo Mistral 7B:       4.5 GB (loaded em GPU/CPU)
Inference Cache:         1.0-2.0 GB (batch processing)
Context Windows:         500 MB-1.0 GB (100 contextos)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL Ollama:            6.0-7.5 GB âš ï¸ (MAIOR CONSUMIDOR)
```

**Justificativa:**
- Mistral 7B prÃ©-carregado na memÃ³ria
- Cada inferÃªncia cria contexto na memÃ³ria
- 100 requisiÃ§Ãµes simultÃ¢neas = 100 processamentos em fila
- Sem GPU dedicada = usa RAM + CPU

---

### 4ï¸âƒ£ **Redis 7-Alpine**
```
Base:                    50 MB
SessÃµes (100 usuÃ¡rios):  50-100 MB
Cache de responses:      100-200 MB
Job metadata (Bull):     100-150 MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL Redis:             300-500 MB
```

**Justificativa:**
- Redis Alpine Ã© leve
- SessÃµes + cache + job queue metadata
- TTL automÃ¡tico (expiraÃ§Ã£o)

---

### 5ï¸âƒ£ **Evolution API (WhatsApp)**
```
Base:                    300 MB
Por conexÃ£o WhatsApp:    10-20 MB
10 conexÃµes:             100-200 MB
Message buffers:         100-200 MB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL Evolution API:     500-700 MB
```

**Justificativa:**
- Evolution API Ã© baseado em Node.js tambÃ©m
- Cada conexÃ£o mantÃ©m estado com WhatsApp
- Buffers de mensagens

---

### 6ï¸âƒ£ **Nginx (Reverse Proxy)**
```
TOTAL Nginx:             50-100 MB
```

---

### 7ï¸âƒ£ **Sistema Operacional + Docker Overhead**
```
Kernel + Docker:         800 MB - 1.2 GB
Buffer cache:            500 MB - 1.0 GB
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TOTAL SO:                1.3-2.2 GB
```

---

## ğŸ’° **RESUMO TOTAL DE CONSUMO**

| Componente | MÃ­nimo | Recomendado | MÃ¡ximo |
|-----------|--------|-------------|--------|
| NestJS Backend | 1.5 GB | 2.0 GB | 2.5 GB |
| PostgreSQL | 2.0 GB | 2.5 GB | 3.5 GB |
| Ollama (LLM) | **6.0 GB** | **7.0 GB** | **8.0 GB** âš ï¸ |
| Redis | 0.3 GB | 0.5 GB | 0.7 GB |
| Evolution API | 0.5 GB | 0.7 GB | 1.0 GB |
| Nginx | 0.05 GB | 0.1 GB | 0.2 GB |
| SO + Docker | 1.3 GB | 1.5 GB | 2.0 GB |
| **Buffer/Reserve** | - | **1.5 GB** | - |
| **â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€** | **â”€â”€â”€â”€â”€â”€â”€** | **â”€â”€â”€â”€â”€â”€â”€** | **â”€â”€â”€â”€â”€â”€â”€** |
| **TOTAL** | **11.6 GB** | **15.8 GB** | **19.9 GB** |

---

## ğŸ–¥ï¸ **RECOMENDAÃ‡Ã•ES DE VPS**

### â­ **OPÃ‡ÃƒO 1: PadrÃ£o (Recomendado)**
```
Processador:   4 vCPU (2.5-3.5 GHz)
MemÃ³ria RAM:   16 GB
Storage:       100 GB SSD
Bandwidth:     Sem limite (5TB+/mÃªs)
Estimado:      $20-30/mÃªs
```

**Por que?**
- 16 GB RAM = 15.8 GB consumo + 0.2 GB margem
- 4 vCPU = adequado para Ollama + NestJS
- Sem gargalo

---

### ğŸ’ª **OPÃ‡ÃƒO 2: Robusta (Recomendado se crescimento)**
```
Processador:   8 vCPU (3.0-4.0 GHz)
MemÃ³ria RAM:   32 GB
Storage:       200 GB SSD (ou NVME)
Bandwidth:     Sem limite (10TB+/mÃªs)
Estimado:      $50-70/mÃªs
```

**Por que?**
- 2x RAM = espaÃ§o para crescimento (20+ usuÃ¡rios)
- 8 vCPU = melhor performance em Ollama
- Headroom para variaÃ§Ãµes de pico

---

### ğŸš€ **OPÃ‡ÃƒO 3: Performance (Para 50+ usuÃ¡rios)**
```
Processador:   16 vCPU + GPU (NVIDIA A100/L40)
MemÃ³ria RAM:   64 GB
Storage:       500 GB NVMe
Bandwidth:     Sem limite (20TB+/mÃªs)
Estimado:      $200-400/mÃªs
```

**Por que?**
- GPU dedicada = 10x mais rÃ¡pido que CPU em LLM
- 64 GB RAM = escalabilidade
- NVME = cache mais rÃ¡pido para Ollama

---

## ğŸ¯ **RECOMENDAÃ‡ÃƒO FINAL: OPÃ‡ÃƒO 1 (16 GB RAM)**

Para 10 usuÃ¡rios Ã— 10 clientes = 100 conversas simultÃ¢neas

```
âœ… ESCOLHA: 4 vCPU + 16 GB RAM + 100 GB SSD
ğŸŒ Provedores sugeridos:
   â€¢ DigitalOcean: Droplet $24/mÃªs
   â€¢ Linode: 16GB $80/mÃªs (mais caro)
   â€¢ Hetzner: CX41 â‚¬27/mÃªs (melhor custo/benefÃ­cio)
   â€¢ AWS: EC2 t3.xlarge ~$200/mÃªs (overkill)
   â€¢ Azure: Standard_D4s_v3 ~$150/mÃªs (overkill)
```

---

## âš™ï¸ **OTIMIZAÃ‡Ã•ES RECOMENDADAS**

### 1ï¸âƒ£ **Ollama - Reduzir Consumo**

**OpÃ§Ã£o A: Modelo mais leve**
```yaml
# Usar Mistral 7B (padrÃ£o: 7.2B parÃ¢metros)
OLLAMA_MODEL=mistral  # Atual

# OU migrar para modelo menor
OLLAMA_MODEL=neural-chat  # 7B, mais rÃ¡pido
# Economia: -1 GB RAM
```

**OpÃ§Ã£o B: QuantizaÃ§Ã£o**
```bash
# ForÃ§ar quantizaÃ§Ã£o Q4 (vs Q8 padrÃ£o)
# Reduz 8GB â†’ 4GB com perda <2% qualidade
ollama run mistral:q4
# Economia: -4 GB RAM
```

---

### 2ï¸âƒ£ **PostgreSQL - Otimizar MemÃ³ria**

```sql
-- Reduzir shared_buffers se RAM limitada
-- /apps/backend/.env.production
POSTGRES_SHARED_BUFFERS=2GB      # 25% de 8GB
POSTGRES_WORK_MEM=10MB           # Por conexÃ£o
POSTGRES_MAX_CONNECTIONS=100

-- Resulta em: 3 GB â†’ 1.5 GB
```

---

### 3ï¸âƒ£ **Redis - Habilitar Eviction**

```bash
# .env.production
REDIS_MAXMEMORY=500MB
REDIS_MAXMEMORY_POLICY=allkeys-lru
# Auto-remove dados antigos
```

---

### 4ï¸âƒ£ **NestJS - Limitar ConexÃµes**

```typescript
// apps/backend/src/main.ts
const server = await app.listen(3000, () => {
  server.maxConnections = 100;  // Limita conexÃµes simultÃ¢neas
  server.keepAliveTimeout = 60000;  // Desconecta inativo
});
```

---

## ğŸ“Š **CONSUMO COM OTIMIZAÃ‡Ã•ES**

Se aplicar todas as otimizaÃ§Ãµes:

| Componente | Original | Otimizado | Economia |
|-----------|----------|-----------|----------|
| Ollama (Q4) | 7.0 GB | 3.0 GB | **-4 GB** |
| PostgreSQL | 2.5 GB | 1.5 GB | **-1 GB** |
| Redis | 0.5 GB | 0.3 GB | **-0.2 GB** |
| **TOTAL** | **15.8 GB** | **9.3 GB** | **-6.5 GB** |

**Resultado:** VPS 8 GB RAM + 2 vCPU seria suficiente (~$10-15/mÃªs) âœ…

---

## ğŸš¨ **MONITORAMENTO EM PRODUÃ‡ÃƒO**

### Alertas importantes:

```bash
# Verificar consumo em tempo real
docker stats

# Alertar se:
# - RAM > 80% (8GB de 10GB)
# - CPU > 85% por 5+ minutos
# - Ollama latÃªncia > 3s

# Comando de monitoramento
watch -n 1 'docker stats --no-stream'
```

---

## ğŸ“‹ **CHECKLIST PRÃ‰-PRODUÃ‡ÃƒO**

- [ ] Escolher VPS com 16 GB RAM (ou 8 GB com otimizaÃ§Ãµes)
- [ ] Configurar alertas de memÃ³ria
- [ ] Testar carga com 100 conexÃµes simultÃ¢neas
- [ ] Habilitar compressÃ£o em Nginx
- [ ] Otimizar Ollama (Q4 quantization)
- [ ] Limpar cache Redis diariamente
- [ ] Backup PostgreSQL a cada 6 horas
- [ ] Monitorar logs de erro
- [ ] Implementar auto-scaling (se cloud)

---

## ğŸ“ **RESUMO EXECUTIVO**

| Pergunta | Resposta |
|----------|----------|
| **Consumo total?** | 15.8 GB RAM (pico: 19.9 GB) |
| **VPS recomendado?** | 4 vCPU + 16 GB RAM |
| **Custo?** | $20-30/mÃªs (bÃ¡sico) |
| **Com otimizaÃ§Ãµes?** | 8 GB RAM suficiente (~$10-15/mÃªs) |
| **Gargalo principal?** | Ollama LLM (6-7 GB) |
| **CPU recomendada?** | 4 cores (4 vCPU) mÃ­nimo |
| **Quanto crescer para 50 usuÃ¡rios?** | 32 GB RAM + 8 vCPU recomendado |
| **Precisa GPU?** | NÃ£o obrigatÃ³ria, mas 10x mais rÃ¡pido |

---

## ğŸ”— **DocumentaÃ§Ã£o Relacionada**

- [FASE11_DEPLOYMENT_GUIDE.md](./FASE11_DEPLOYMENT_GUIDE.md) - ConfiguraÃ§Ã£o de produÃ§Ã£o
- [infra/PRODUCTION_README.md](./infra/PRODUCTION_README.md) - OperaÃ§Ãµes
- [docker-compose.yml](./infra/docker-compose.yml) - ConfiguraÃ§Ã£o dos serviÃ§os
